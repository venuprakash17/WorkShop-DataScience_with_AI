{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5587e5e",
   "metadata": {},
   "source": [
    "# E-Commerce EDA — Simplified Notebook\n",
    "\n",
    "This simplified notebook contains the same sections and outcomes as the previous version,\n",
    "but uses **easy-to-read code** and **line-by-line comments** so students can follow quickly.\n",
    "\n",
    "Sections: Load → Clean → Univariate → Bivariate → Multivariate → Segments → Derived metrics → Time-series → Save\n",
    "\n",
    "Each code cell contains short comments explaining what each variable/line does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5195fcd1",
   "metadata": {},
   "source": [
    "## 0. Imports & plotting settings\n",
    "\n",
    "**Why:** Load standard libraries and set a clean plotting style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9405b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready. DATA_PATH: Realistic_E-Commerce_Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Basic imports\n",
    "import pandas as pd              # for data manipulation (tables)\n",
    "import numpy as np               # for numeric operations\n",
    "import matplotlib.pyplot as plt  # for plotting charts\n",
    "import os                        # for file path checks\n",
    "\n",
    "# Make charts look clean and readable\n",
    "plt.style.use('ggplot')          # a simple, presentation-friendly style\n",
    "plt.rcParams['figure.dpi'] = 110\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Paths for the dataset and cleaned output\n",
    "DATA_PATH = \"Realistic_E-Commerce_Dataset.csv\"\n",
    "\n",
    "print(\"Ready. DATA_PATH:\", DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a882a",
   "metadata": {},
   "source": [
    "## 1. Load dataset\n",
    "\n",
    "**Why:** Confirm file exists and inspect first rows to form hypotheses.\n",
    "\n",
    "**Outcome:** Know dataset shape and column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e7f96b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Realistic_E-Commerce_Dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check the file exists\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# if not os.path.exists(DATA_PATH):\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     raise FileNotFoundError(f\"Please upload the CSV to {DATA_PATH}\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Read CSV into a pandas DataFrame\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print shape (#rows, #columns) and show first 5 rows\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape:\u001b[39m\u001b[38;5;124m'\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape)   \u001b[38;5;66;03m# number of rows and columns\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Realistic_E-Commerce_Dataset.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check the file exists\n",
    "# if not os.path.exists(DATA_PATH):\n",
    "#     raise FileNotFoundError(f\"Please upload the CSV to {DATA_PATH}\")\n",
    "\n",
    "# Read CSV into a pandas DataFrame\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Print shape (#rows, #columns) and show first 5 rows\n",
    "print('Shape:', df.shape)   # number of rows and columns\n",
    "print('\\nColumns:', list(df.columns))  # list of column names\n",
    "display(df.head())          # show first 5 rows for a quick look\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3353dd",
   "metadata": {},
   "source": [
    "## 2. Quick summary & missing values\n",
    "\n",
    "**Why:** See basic statistics and missing counts to guide cleaning.\n",
    "\n",
    "**Outcome:** Decide imputation and type fixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c15a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic numeric summary\n",
    "numeric = df.select_dtypes(include=[np.number])\n",
    "print('Numeric columns summary:')\n",
    "display(numeric.describe().T)   # mean, std, min, max for numeric features\n",
    "\n",
    "# Missing values per column\n",
    "print('\\nMissing values per column:')\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "display(missing.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef71d61",
   "metadata": {},
   "source": [
    "## 3. Clean types and parse dates\n",
    "\n",
    "**Why:** Convert columns to correct types, especially `date` for time analysis.\n",
    "\n",
    "**Outcome:** Ready for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parse 'date' column to datetime so we can extract hour/day later\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')  # convert strings to datetime; invalid -> NaT\n",
    "\n",
    "# Convert integer-like columns safely (preserve NA)\n",
    "int_cols = ['user_id','session_id','age','time_spent_minutes','pages_viewed','scroll_depth','clicks','wishlist_items','cart_items']\n",
    "for col in int_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')  # non-numeric -> NaN\n",
    "\n",
    "# Show dtypes after conversion\n",
    "print('Dtypes after conversions:')\n",
    "print(df.dtypes.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86caf6",
   "metadata": {},
   "source": [
    "## 4. (Optional) Inject a few missing values for demo\n",
    "\n",
    "**Why:** If dataset has no missing values, create a few for imputation.\n",
    "\n",
    "**Outcome:** A few controlled missing values to practice filling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3acedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Only inject if data has zero missing values (keeps original data otherwise)\n",
    "if df.isna().sum().sum() == 0:\n",
    "    rng = np.random.default_rng(1)\n",
    "    idx = rng.choice(df.index, size=6, replace=False)\n",
    "    # Make some ages missing\n",
    "    if 'age' in df.columns:\n",
    "        df.loc[idx[:2], 'age'] = np.nan\n",
    "    # Make time_spent_minutes missing\n",
    "    if 'time_spent_minutes' in df.columns:\n",
    "        df.loc[idx[2:4], 'time_spent_minutes'] = np.nan\n",
    "    # Make product_category missing\n",
    "    if 'product_category' in df.columns:\n",
    "        df.loc[idx[4:], 'product_category'] = np.nan\n",
    "    print('Injected missing at indices:', list(idx))\n",
    "else:\n",
    "    print('Dataset already has missing values; no injection done.')\n",
    "\n",
    "# Show missing summary\n",
    "display(df.isna().sum().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fefdc0",
   "metadata": {},
   "source": [
    "## 5. Imputation (simple and explainable)\n",
    "\n",
    "**Why:** Fill missing values so plots and models run without errors. We'll use median for numbers and 'Unknown' for categories.\n",
    "\n",
    "**Outcome:** Cleaned columns ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffbfa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fill numeric missing values with median (explainable and robust to outliers)\n",
    "for col in ['age','time_spent_minutes']:\n",
    "    if col in df.columns:\n",
    "        median = df[col].median(skipna=True)\n",
    "        df[col] = df[col].fillna(median)\n",
    "        print(f'Filled {col} missing with median =', median)\n",
    "\n",
    "# Fill categorical missing with 'Unknown' so they become a category\n",
    "if 'product_category' in df.columns:\n",
    "    df['product_category'] = df['product_category'].fillna('Unknown')\n",
    "    print('Filled product_category missing with Unknown')\n",
    "\n",
    "# Quick check\n",
    "display(df.isna().sum().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f8218c",
   "metadata": {},
   "source": [
    "## 6. Derived features (simple and useful)\n",
    "\n",
    "**Why:** These features help capture behavior and time patterns. Each line is commented.\n",
    "\n",
    "**Outcome:** New, interpretable features for EDA and later modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day of week and hour from the timestamp\n",
    "if 'date' in df.columns:\n",
    "    # Use the .dt accessor to access datetime properties\n",
    "    df['day_of_week'] = df['date'].dt.day_name()   # Monday, Tuesday, ...\n",
    "    df['hour'] = df['date'].dt.hour               # 0-23 hour of the day\n",
    "else:\n",
    "    df['day_of_week'] = 'Unknown'\n",
    "    df['hour'] = 0\n",
    "\n",
    "# Age groups: simple bins\n",
    "df['age_group'] = pd.cut(df['age'], bins=[17,25,40,65], labels=['18-25','26-40','41-65'])\n",
    "\n",
    "# cart_to_wishlist_ratio: intent measure (cart items divided by wishlist size)\n",
    "df['cart_to_wishlist_ratio'] = df.apply(lambda r: (r['cart_items'] / r['wishlist_items']) if (r.get('wishlist_items',0) and r['wishlist_items']>0) else r['cart_items'], axis=1)\n",
    "\n",
    "# engagement_score: small composite metric from time, pages, clicks (weights are chosen for simplicity)\n",
    "df['engagement_score'] = (df['time_spent_minutes']/60)*0.4 + (df['pages_viewed']/20)*0.35 + (df['clicks']/50)*0.25\n",
    "\n",
    "# value_per_cart_item: avg session value divided by cart items (fallback to avg if cart is zero)\n",
    "df['value_per_cart_item'] = df.apply(lambda r: (r['avg_session_value']/r['cart_items']) if (r.get('cart_items',0) and r['cart_items']>0) else r['avg_session_value'], axis=1)\n",
    "\n",
    "# Show a few rows with derived columns\n",
    "display(df[['date','age','age_group','hour','cart_items','wishlist_items','cart_to_wishlist_ratio','engagement_score','value_per_cart_item']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb86881d",
   "metadata": {},
   "source": [
    "## 7. Univariate EDA — Numeric features (simple plots)\n",
    "\n",
    "**Why:** See the shape of numeric features. We annotate mean and median for clarity.\n",
    "\n",
    "**Outcome:** Students can spot skew and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd844e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = ['age','time_spent_minutes','pages_viewed','avg_session_value','engagement_score','value_per_cart_item']\n",
    "\n",
    "for col in num_cols:\n",
    "    if col in df.columns:\n",
    "        data = df[col].dropna()\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.hist(data, bins=20, edgecolor='black')\n",
    "        plt.title(col)\n",
    "        # show mean and median lines\n",
    "        plt.axvline(data.mean(), color='red', linestyle='--', label=f'mean={data.mean():.1f}')\n",
    "        plt.axvline(data.median(), color='black', linestyle='-', label=f'median={data.median():.1f}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # print short outcome\n",
    "        print(f\"{col} -> mean: {data.mean():.2f}, median: {data.median():.2f}, missing: {data.isna().sum()}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f80f4",
   "metadata": {},
   "source": [
    "## 8. Univariate EDA — Categorical features (counts)\n",
    "\n",
    "**Why:** Identify dominant categories which affect encoding and sampling.\n",
    "\n",
    "**Outcome:** We list top categories for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d40b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_cols = ['gender','product_category','membership_status','device_type','traffic_source','time_of_day']\n",
    "\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        counts = df[col].value_counts()\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.bar(counts.index.astype(str), counts.values)\n",
    "        plt.title(col)\n",
    "        plt.xticks(rotation=30)\n",
    "        plt.show()\n",
    "        print(f\"{col} top 3: {list(counts.head(3).index)} -> counts {list(counts.head(3).values)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2171ec3",
   "metadata": {},
   "source": [
    "## 9. Target variable `purchase` (balance)\n",
    "\n",
    "**Why:** Check how balanced the target is; influences modeling choices.\n",
    "\n",
    "**Outcome:** Observe purchase percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c346a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the DataFrame has a column named 'purchase'\n",
    "# Calculate purchase rate (mean works since values are 0/1 → fraction of 1s)\n",
    "rate = df['purchase'].mean()\n",
    "    \n",
    "    # Create a pie chart showing Yes vs No purchases\n",
    "plt.pie(\n",
    "        [1 - rate, rate],                          # proportions: No vs Yes\n",
    "        labels=[f'No ({1-rate:.1%})', f'Yes ({rate:.1%})'],  # labels with percentages\n",
    "        autopct='%1.1f%%'                          # show percentages inside the pie\n",
    ")\n",
    "    \n",
    "    # Add chart title\n",
    "plt.title('Purchase Rate')\n",
    "    \n",
    "    # Display the chart\n",
    "plt.show()\n",
    "    \n",
    "    # Print purchase rate rounded to 3 decimal places\n",
    "print(f'Purchase rate = {rate:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c9a432",
   "metadata": {},
   "source": [
    "## 10. Bivariate — Numeric vs purchase (boxplots)\n",
    "\n",
    "**Why:** Check whether numeric features differ for purchasers vs non-purchasers.\n",
    "\n",
    "**Outcome:** Compare medians; higher median often means the feature is predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = ['time_spent_minutes','pages_viewed','engagement_score','value_per_cart_item']\n",
    "\n",
    "for col in cols:\n",
    "    if col in df.columns and 'purchase' in df.columns:\n",
    "        no = df[df['purchase']==0][col].dropna()\n",
    "        yes = df[df['purchase']==1][col].dropna()\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.boxplot([no, yes], labels=['No','Yes'])\n",
    "        plt.title(f'{col} by Purchase')\n",
    "        plt.show()\n",
    "        print(f'{col} medians -> No: {no.median():.2f}, Yes: {yes.median():.2f}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd18120",
   "metadata": {},
   "source": [
    "## 11. Bivariate — Categorical vs purchase (conversion rates)\n",
    "\n",
    "**Why:** Find top converting categories to prioritize targeting.\n",
    "\n",
    "**Outcome:** List top converters for each categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3637722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_list = ['product_category','membership_status','gender','device_type','traffic_source','time_of_day']\n",
    "\n",
    "for col in cat_list:\n",
    "    if col in df.columns and 'purchase' in df.columns:\n",
    "        conv = df.groupby(col)['purchase'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        # Plot a bar chart\n",
    "        plt.bar(conv.index.astype(str), conv.values)\n",
    "        plt.title(f'Conversion by {col}')\n",
    "        plt.xticks(rotation=30)\n",
    "        plt.show()\n",
    "        \n",
    "        # Print top 3 converters\n",
    "        print(f'Top converters in {col}:', conv.head(3).round(3).to_dict(), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1629c51",
   "metadata": {},
   "source": [
    "## 12. Multivariate — Correlation matrix\n",
    "\n",
    "**Why:** See which numeric features are correlated. Helps avoid multicollinearity.\n",
    "\n",
    "**Outcome:** Table and heatmap of correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5422c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Numeric correlations\n",
    "num = df.select_dtypes(include=[np.number]).copy()\n",
    "corr = num.corr()\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.title('Correlation matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print top correlated pairs (absolute value)\n",
    "pairs = corr.abs().unstack().sort_values(ascending=False)\n",
    "pairs = pairs[pairs < 0.9999]  # remove self-correlation\n",
    "top = pairs.drop_duplicates().head(8)\n",
    "display(top.reset_index().rename(columns={'level_0':'f1','level_1':'f2',0:'abs_corr'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400264cc",
   "metadata": {},
   "source": [
    "## 13. Pairwise scatter (sample)\n",
    "\n",
    "**Why:** Quick visual check for relationships; sample rows to keep plots readable.\n",
    "\n",
    "**Outcome:** Spot obvious clusters or trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f20d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_cols = ['time_spent_minutes','pages_viewed','avg_session_value','engagement_score']\n",
    "available = [c for c in sample_cols if c in df.columns]\n",
    "if len(available) >= 2:\n",
    "    sample = df[available].sample(n=min(200, len(df)), random_state=2)\n",
    "    pd.plotting.scatter_matrix(sample, diagonal='hist', figsize=(8,8))\n",
    "    plt.suptitle('Scatter matrix (sample)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Not enough columns for scatter matrix.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dbe7e3",
   "metadata": {},
   "source": [
    "## 14. Segmented analysis — pivot & grouped view\n",
    "\n",
    "**Why:** Look at combinations like membership × product to prioritize segments.\n",
    "\n",
    "**Outcome:** Pivot table and a small bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09121bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pivot: membership_status x product_category conversion\n",
    "if 'membership_status' in df.columns and 'product_category' in df.columns:\n",
    "    pivot = df.pivot_table(index='membership_status', columns='product_category', values='purchase', aggfunc='mean')\n",
    "    display(pivot.round(3))\n",
    "    # Plot membership conversion overall\n",
    "    mem = df.groupby('membership_status')['purchase'].mean()\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.bar(mem.index, mem.values)\n",
    "    plt.title('Conversion by membership_status')\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f169d3",
   "metadata": {},
   "source": [
    "## 15. Derived metrics — check usefulness\n",
    "\n",
    "**Why:** See whether engagement_score and cart_to_wishlist_ratio separate purchasers.\n",
    "\n",
    "**Outcome:** Boxplots and medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b859b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'engagement_score' in df.columns and 'purchase' in df.columns:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.boxplot([df[df['purchase']==0]['engagement_score'], df[df['purchase']==1]['engagement_score']], labels=['No','Yes'])\n",
    "    plt.title('Engagement score by purchase')\n",
    "    plt.show()\n",
    "    print('engagement_score medians ->', df.groupby('purchase')['engagement_score'].median().to_dict())\n",
    "\n",
    "if 'cart_to_wishlist_ratio' in df.columns and 'purchase' in df.columns:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.boxplot([df[df['purchase']==0]['cart_to_wishlist_ratio'], df[df['purchase']==1]['cart_to_wishlist_ratio']], labels=['No','Yes'])\n",
    "    plt.title('Cart-to-wishlist ratio by purchase')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8627155e",
   "metadata": {},
   "source": [
    "## 16. Time-series — daily & hourly patterns\n",
    "\n",
    "**Why:** Find times/days with higher conversion; helpful for scheduling campaigns.\n",
    "\n",
    "**Outcome:** Line plots of daily purchase rate and hourly conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9383b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'date' in df.columns and 'purchase' in df.columns:\n",
    "    df['date_only'] = df['date'].dt.date\n",
    "    daily = df.groupby('date_only').agg(total=('purchase','count'), purchases=('purchase','sum'))\n",
    "    daily['rate'] = daily['purchases'] / daily['total']\n",
    "\n",
    "    plt.figure(figsize=(9,3))\n",
    "    plt.plot(daily.index, daily['rate'], marker='o')\n",
    "    plt.title('Daily purchase rate')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # Hourly conversion\n",
    "    hourly = df.groupby('hour')['purchase'].mean()\n",
    "    plt.figure(figsize=(7,3))\n",
    "    plt.plot(hourly.index, hourly.values, marker='o')\n",
    "    plt.title('Hourly purchase rate')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Missing date or purchase column.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b041cb03",
   "metadata": {},
   "source": [
    "## 17. Summary & next steps\n",
    "\n",
    "**Summary:**\n",
    "- The notebook is simplified for student consumption.\n",
    "- Key signals: engagement, pages viewed, cart behavior, membership.\n",
    "\n",
    "**Next steps:** Build preprocessing pipeline, train baseline models, evaluate with business-driven metrics, deploy a prediction API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b7c0de-f109-492d-b1e3-4dee480cd230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
